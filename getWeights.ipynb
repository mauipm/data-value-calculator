{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime as dtime\n",
    "from ast import literal_eval\n",
    "import time\n",
    "from pyaltmetric import Altmetric\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Zeilen und Spalten des DataFrames anzeigen\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSSdata(paperId):\n",
    "  \n",
    "  #######################\n",
    "  #     SEND REQUEST    #\n",
    "  #######################\n",
    "  try:\n",
    "    api_key = 'rGUKYOEpCP2FKQK88CLuB1izZBvDiQwA5SsSZ5vo'\n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/\"+paperId.replace(' ', '').strip()+\"?fields=title,referenceCount,citationCount,influentialCitationCount,externalIds,authors.hIndex,authors.paperCount,authors.citationCount,authors.affiliations,authors.paperCount,authors.name,fieldsOfStudy,publicationTypes,publicationDate,year,journal,isOpenAccess\"\n",
    "    req = requests.get(url=url, params={'x-api-key': api_key}).json()\n",
    "\n",
    "    # Wait 5 Minutes and retry if API-Server sends 'Too Many Requests'\n",
    "    while req.get('message') == 'Too Many Requests':\n",
    "      print('[Too Many Requests]: Waiting 5 minutes.')\n",
    "      time.sleep((60*5)+5) # Wait 5 Minutes + 5 Extra-seconds for tolerance\n",
    "      req = requests.get(url=url, params={'x-api-key': api_key}).json()\n",
    "\n",
    "    ############################\n",
    "    #     PROCESS RESPONSE     #\n",
    "    ############################\n",
    "    df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in req.items() ]));\n",
    "\n",
    "    # Features aus verschachteltem JSON-Array extrahieren und in separate Spalten teilen\n",
    "    for col in ['DOI', 'CorpusId']:\n",
    "      try:\n",
    "        df[col] = df.loc[col].externalIds\n",
    "      except:\n",
    "        df[col] = np.nan\n",
    "    \n",
    "    df['paperId'] = df['paperId'].iloc[0]\n",
    "    df['title'] = df['title'].iloc[0]\n",
    "    df = df[df['externalIds'].isna()]\n",
    "    df['journal_name'] = df.loc['name'].journal if df.loc['name'].journal else np.nan\n",
    "\n",
    "    # Belegte Seiten des Journals in dem das Paper veröffentlicht wurde berechnen\n",
    "    try:\n",
    "        # Manche Angaben werden in ihrer Schreibweise verkürzt... z.B.: 153-57, dies soll wie 153-157 behandelt werden, da sonst negative Zahlen bei der folgenden Berechnung entstehen.\n",
    "        df['journal_pages_occupiedCount'] = extractOccupiedJournalPagesCount(df.loc['pages'].journal)\n",
    "    except:\n",
    "        df['journal_pages_occupiedCount'] = 0\n",
    "\n",
    "    # MV filtern\n",
    "    df = df[~df['authors'].isna()][['DOI', 'CorpusId', 'paperId', 'title', 'referenceCount', 'citationCount', 'influentialCitationCount', 'fieldsOfStudy', 'publicationTypes', 'journal_name', 'journal_pages_occupiedCount', 'isOpenAccess', 'publicationDate', 'year', 'authors']]\n",
    "\n",
    "    # Author Name extrahieren\n",
    "    df['author_names'] = df['authors'].apply(lambda x: x['name'])\n",
    "    df['author_names'] = str(df['author_names'].to_list())\n",
    "    df['author_names'] = df['author_names'].apply(literal_eval)\n",
    "\n",
    "    # # Author Affiliation extrahieren\n",
    "    # df['authors_affiliations'] = df['authors'].apply(lambda x: x['affiliations'])\n",
    "    # df['authors_affiliations'] = str(df[~df['authors_affiliations'].isna()]['authors_affiliations'].to_list())\n",
    "    # df['authors_affiliations'] = df['author_affiliations'].apply(literal_eval)\n",
    "\n",
    "    # h-Index aller Autoren extrahieren\n",
    "    df['hIndex'] = df['authors'].apply(lambda x: x['hIndex'])\n",
    "\n",
    "    # Avg, min, max h-Index über alle Autoren berechnen, runden und in Ganzzahl umwandeln\n",
    "    df['authors_sum_hIndex'] = df['hIndex'].sum().round(0).astype(int)\n",
    "    # df['authors_mean_hIndex'] = df['hIndex'].mean().round(0).astype(int)\n",
    "    # df['authors_max_hIndex'] = df['hIndex'].max().round(0).astype(int)\n",
    "    # df['authors_min_hIndex'] = df['hIndex'].min().round(0).astype(int)\n",
    "\n",
    "    # paperCount aller Autoren extrahieren\n",
    "    df['author_paperCount'] = df['authors'].apply(lambda x: x['paperCount'])\n",
    "\n",
    "    # Avg, min, max paperCount über alle Autoren berechnen, runden und in Ganzzahl umwandeln\n",
    "    df['authors_sum_paperCount'] = df['author_paperCount'].sum().round(0).astype(int)\n",
    "    # df['authors_mean_paperCount'] = df['author_paperCount'].mean().round(0).astype(int)\n",
    "    # df['authors_max_paperCount'] = df['author_paperCount'].max().round(0).astype(int)\n",
    "    # df['authors_min_paperCount'] = df['author_paperCount'].min().round(0).astype(int)\n",
    "\n",
    "    # citationCount aller Autoren extrahieren\n",
    "    df['author_citationCount'] = df['authors'].apply(lambda x: x['citationCount'])\n",
    "\n",
    "    # Avg, min, max citationCount über alle Autoren berechnen, runden und in Ganzzahl umwandeln\n",
    "    df['authors_sum_citationCount'] = df['author_citationCount'].sum().round(0).astype(int)\n",
    "    # df['authors_mean_citationCount'] = df['author_citationCount'].mean().round(0).astype(int)\n",
    "    # df['authors_max_citationCount'] = df['author_citationCount'].max().round(0).astype(int)\n",
    "    # df['authors_min_citationCount'] = df['author_citationCount'].min().round(0).astype(int)\n",
    "\n",
    "    df['authorsCount'] = len(df['author_names'])\n",
    "\n",
    "    # Redundante bzw. irrelevante Features entfernen\n",
    "    df = df.iloc[0][['DOI', 'CorpusId', 'paperId', 'title', 'author_names', 'isOpenAccess', 'publicationTypes', 'journal_name', 'journal_pages_occupiedCount', 'publicationDate', 'year', 'fieldsOfStudy', 'referenceCount', 'citationCount', 'authorsCount', 'authors_sum_hIndex', 'authors_sum_paperCount', 'authors_sum_citationCount']]\n",
    "\n",
    "    # Datentyp in Ganzzahl umwandeln\n",
    "    df['referenceCount'] = df['referenceCount'].astype(int)\n",
    "    df['citationCount'] = df['citationCount'].astype(int)\n",
    "    # df['influentialCitationCount'] = df['influentialCitationCount'].astype(int)\n",
    "    if df['year']:\n",
    "      df['year'] = df['year'].astype(int)\n",
    "\n",
    "    # print('- Collected Semantic Scholar metadata.')\n",
    "    return df\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Nobel Prize winners <br> see: https://www.nobelprize.org/about/api-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://api.nobelprize.org/v1/prize.json'\n",
    "search_query = '?year=1900&yearto='+str(datetime.datetime.now().year)\n",
    "# search_query = '?category=medicine&year=1990&yearto=1994'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelprize_data = requests.get(base_url+search_query).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelprize_df = pd.DataFrame(nobelprize_data.get('prizes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAuthorNames(laureates_col):\n",
    "    laureates = []\n",
    "    if laureates_col:\n",
    "        try:\n",
    "            for i in laureates_col:\n",
    "                surname = i.get('surname')\n",
    "                firstname = i.get('firstname')\n",
    "                if surname:\n",
    "                    full_name = firstname[0] + '. ' + surname\n",
    "                    laureates.append(full_name)\n",
    "                elif surname==None:\n",
    "                    laureates.append(firstname)\n",
    "                return laureates\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelprize_df['laureates'] = nobelprize_df['laureates'].apply(lambda x: extractAuthorNames(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelprize_df.drop('overallMotivation', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Nobelprize winners\n",
    "nobelprize_laureates = nobelprize_df.explode('laureates')['laureates'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nobelprize_laureates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNobelPrizeLaureate(authors):\n",
    "    # year = df['year']\n",
    "    # fos = df['fieldsOfStudy']\n",
    "    isNobelPrizeLaureate = False\n",
    "\n",
    "    for author in authors:\n",
    "        if author.lower() in [str(item).lower() for item in nobelprize_laureates]:\n",
    "            isNobelPrizeLaureate = True\n",
    "    \n",
    "    # print('- Checked if paper has Nobel Prize Laureate as contributer.')\n",
    "    return isNobelPrizeLaureate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNobelPrizeLaureateCount(authors):\n",
    "    nobelPrizeLaureateCount = 0\n",
    "\n",
    "    for author in authors:\n",
    "        if author.lower() in [str(item).lower() for item in nobelprize_laureates]:\n",
    "            nobelPrizeLaureateCount+=1\n",
    "    \n",
    "    # print('- Checked if paper has Nobel Prize Laureate as contributer.')\n",
    "    return nobelPrizeLaureateCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss_df['hasNobelPrizeLaureate'] = hasNobelPrizeLaureate(ss_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAMdata(paper_doi):\n",
    "\n",
    "    try:\n",
    "        # Altmetric-Objekt erstellen\n",
    "        a = Altmetric()\n",
    "\n",
    "        # In Altmetric-DB nach Paper mit entsprechender DOI suchen (API antwortet mit JSON-Array)\n",
    "        altmetric_json_data = a.doi(paper_doi)\n",
    "\n",
    "        # DataFrame erstellen und in geeignetes Format transformieren\n",
    "        df = pd.DataFrame.from_dict(altmetric_json_data.items()).transpose()\n",
    "\n",
    "        # DataFrame filtern\n",
    "        df.columns = df.iloc[0]\n",
    "\n",
    "        # Altmetric Score aufrunden\n",
    "        df = df.iloc[1]\n",
    "        df['score'] = np.ceil(df['score']).astype(int)\n",
    "\n",
    "        # Alle Spalten extrahieren, die 'count' oder/und 'score' enthalten (z.B. gibt es nicht bei jedem Paper die Information wie viele Reddit, Wikipedia etc. Einträge vorhanden sind)\n",
    "        col_list = []\n",
    "        for col in df.keys():\n",
    "            if any(x in col for x in ['count', 'score', 'doi']):\n",
    "                col_list.append(col)\n",
    "\n",
    "        # DataFrame nach den extrahierten Spalten filtern\n",
    "        df = df[col_list]\n",
    "\n",
    "        # Spalten umbennenen, damit zum Schluß nach dem Konkatenieren leichter nachvollzogen werden kann, aus welcher Quelle die Daten stammen.\n",
    "        for col in df.keys():\n",
    "            if col in col_list:\n",
    "                df.rename({col:'altmetric_'+col}, inplace=True)\n",
    "\n",
    "        # print('- altmetric_score: ' + str(df['altmetric_score']))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # return pd.DataFrame()\n",
    "        # print(e)\n",
    "        print('---------- No Data found for <' + str(paper_doi) + '> ----------')\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paperlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamza_paper_list = [\n",
    "    # Agricultural and Food Sciences - Prizewinners                      (Hamza)\n",
    "    '9151910efb402f695ec52f006c5628fb29791d49',\n",
    "    'c1bb306d07f67d1989783ad32a636dfca44d1edf',\n",
    "    '06c541de524d2352116ef3c6a0af318a1b83cf1c',\n",
    "    '083a8f455e8bdf3c9d72ac81c8215db5b09def68',\n",
    "    'b2406cc0373f521897a046108a48c21e7c08f9ca',\n",
    "    '8e076cc26a432ca104dbcb592814405264817363',\n",
    "    '42b777abf798e34df20df87a43d489af7fd4f2c2',\n",
    "    '66b460039fdb0b87c82030cebd3cc224b2763da1',\n",
    "    'e932c974074cc4a38f02fa7d674932eef81faf61',\n",
    "    '613c5dae158288ec4aae6bca752ec1a56d6cdfbc',\n",
    "    # Art - Citation Count\n",
    "    '16b4fd36ff5ca603fed13a326054cd0373ea442c',\n",
    "    '08f383a84d6d3f6f44c1a3f0296455baeea2930d',\n",
    "    'ede81710759ae46afd4634bc847e4c01adeb000c',\n",
    "    'e6ac191117f8e556f85a4b53debeb6acfa51381d',\n",
    "    'ce1323ffc943f3ccccf7b9d0e74db4d57fc290cd',\n",
    "    '3c9dc71914a48574811458ce0056831a0fa31f52',\n",
    "    '405dea794fe583b910f8ff4b147d91350e4f33f3',\n",
    "    '2c411a12f33f15451e1659a3435391962c0cc144',\n",
    "    '55545d2c73cce5d3f2ad42f04b6cbcee5a2d4144',\n",
    "    # Biology - Prizewinners\n",
    "    '1a7af416aa387606d3645ff3b4513a3d5b95e3d8',\n",
    "    '672def367c49ba4463825d5a771d6a5f48fefb99',\n",
    "    '0107ab33dc0e27934ca11c826cc65852b1ea53fb',\n",
    "    '105ddd9b36341cc5135c8fd7fd8dc4d621b758cf',\n",
    "    'bdeb51634bca711d7bb0d31d168262279b74520f',\n",
    "    # Biology - Citation Count\n",
    "    'a411f6a0e6473137ac1a538f7cee65722fa3584f',\n",
    "    'fd495d6cf7c3169bc58550fdf32be6e16e2800f8',\n",
    "    '82e320e06b1c717b0d924d257aa7b6710f53a38e',\n",
    "    '61a28477008aef4f7cabacdd6ec9f42e3b1d9214',\n",
    "    '30eecc8a7b7346a5e0c3a6648b0e156faad3a786',\n",
    "    # Business - Prizewinners\n",
    "    'c619e6fbebab17037b6aff18890f79e7a0c85841',\n",
    "    'bbf2d2cb15c0c6db231a09ad4f51e2b24b20b5dc',\n",
    "    'e2d9ef600adcf0a2e8252777cf5e4d917e99b212',\n",
    "    'c130a72466976096230a31c23f4201f13ce33ea5',\n",
    "    # Business - Citation Count\n",
    "    '12be757eabdaf30457b14e06b510a76d7c4e0328',\n",
    "    '8f53f3d9b99b00a44b8a1554c01bde274dd1ebe9',\n",
    "    'eb7c608c63e71dac1d0c45711ad52989c54ea1fc',\n",
    "    '7bd9a25227ca4378b86a78994817988863a54b60',\n",
    "    'e87c3be7aaa1c7ce91f94fda0815339ac02af787',\n",
    "    'a5b65b05c765025b30503a3705a13a5c490c2fde',\n",
    "    # Computer Science - Prizewinners\n",
    "    '8964838cb60e31c13fda81e10fa75f476e10a126',\n",
    "    # 'DOI:10.1145/323779.323751', NONE-TYPE\n",
    "    '8854e412a9367a76deb2168407bb3aa065009abd',\n",
    "    '07a152ad1c17b35396d8b372cbde16e89705c7ec',\n",
    "    'ebefbee5e96fc2217d651266eb35a0759672e7ca',\n",
    "    # Computer Science - Citation Count\n",
    "    '8ae2c7b50bf64d8d647afad24d95c12a79656da3',\n",
    "    # 'DOI:10.1007/978-1-84882-935-0', NONE-TYPE\n",
    "    '7c72b917a38b09e6d3ab19d28a4344ba54edb6ae',\n",
    "    # 'DOI:10.2307/2322693', NONE-TYPE\n",
    "    'd2d36f50543c65594548953674c26c96295afdd5',\n",
    "    # Chemistry - Prizewinners\n",
    "    'b5b2a56539b2da468790b5d690efb7d345344e65',\n",
    "    'f2259c97773f8e7f5502b588e275546dad142086',\n",
    "    '58aae2c2c9b059124f7168af4611059d6c4fa224',\n",
    "    '2e2414231b6c9c8e707d48c3820ceea0e12dc3c7',\n",
    "    'e3fc26b64a26bc22336ec3e95c540f0042dbce61',\n",
    "    # Chemistry - Citation Count\n",
    "    '05b9e01b36be8f688cdbd7131b89920fa46ac048',\n",
    "    '88e23044396b7c63e831ad0195b6184ea3a12097',\n",
    "    'e0b46e54a742c077006418a7e132e8105371829f',\n",
    "    'ea77a4ba7d6cab863de3e8c5e11fcfc850d51c02',\n",
    "    'c5d7b0fafdd72f57f2b0bfdd0ce3608a2528b666',\n",
    "    # Economics - Prizewinners\n",
    "    'a09892f1d156cdc07532aec355bb55df18c5885e',\n",
    "    'b35af322333811bd16eb5b569466ad76909c0a20',\n",
    "    '2d28a52e59005b2d3e23c9366be880a960dc1eaf',\n",
    "    '00167b90b8fbf57d22b661c32ee8fb39020af12f',\n",
    "    'fbadde2bf6e2b657dc81c5453f920a979d6967f7',\n",
    "    # Economics - Citation Count\n",
    "    'b6d7e6a2763da443c3386edfe70bf46c07059da1',\n",
    "    '72910077a29caf411dbb03148997c72b47e65ab0',\n",
    "    'c04677651cb0545ccf080abeb0958fc907f70c4a',\n",
    "    'a6462e546ad432ddbe3e7d9e5854f029204f57e6',\n",
    "    '6732435ab6e0eb4e0d14662cf724f3be54807a35',\n",
    "    # Education - Prizewinners\n",
    "    '0494a3422778413abca5a53932d8344347c033e3',\n",
    "    '9930b98abeb97374c73cf359cb61521b6ad3d535',\n",
    "    'dc3e4d8f60dccde3e0ea99bc6ed768e14fc4eb3d',\n",
    "    '2096ac46a56a1fbeb1f4008894c3ca62b34c4893',\n",
    "    '5f9ce9c565eadc52ca79ec205f64c59e488d56f8',\n",
    "    # Education - Citation Count\n",
    "    '94e8a06db15e275e82b98529e475c6c17a342300',\n",
    "    'cee6c4973596fb320af3d871bf1920c8bc376adc',\n",
    "    'bc00faabf97a200b359ffbf221d293e20fe03a89',\n",
    "    '8d108f98cd67a98b3f48dade99c2cd13028d28b9',\n",
    "    'd8c69675f42bffffda030e61c2893deca92513fe'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "maurice_paper_list = [\n",
    "    # Engineering - Prizewinners (Charles Stark Draper Prize, ASME Medal)                                 (Maurice)\n",
    "    '39aad6b860cab181a77ec32809f55d4ebb348335',\n",
    "    '16b52fed612e06f0d2a038e981e81e18d0eea14a',\n",
    "    'ce65f83ca6cbe47f96194ad0e992ec8b7f500bbc',\n",
    "    '34e22b27e9ad9421f8fa541da3a28b9909823fc8',\n",
    "    '392bca415565c3a38c52446c95d6a1e88ec49e1a',\n",
    "    '5723cb47076163a974f002bdd03b001976ae8185',\n",
    "    # Engineering - Citation Count\n",
    "    '896172e1d3a5d8a06ce6ef0187f53f1cf3803755',\n",
    "    'a905bb6b0da059d854548f7c34b0cddad9a3b529',\n",
    "    '0b9193580334b1529287aed6a91d1221f09126dd',\n",
    "    '989081b60ae3cf4ecc7a0f739038bfaf61ea9b9e',\n",
    "    'f4b83189b475ec53a85ff99be51b7c3ac93c846d',\n",
    "    # Environmental Science - Prizewinners (Tyler Prize for Environmental Achievement)\n",
    "    '79b4b48c6481becde78bd6287386d6507dac27b1',\n",
    "    'e334406eda2f5e5f9f4783b5b741d4d324b0ac64',\n",
    "    '45c675bb104824664e6b5dba9ff65c5c58e39bb5',\n",
    "    '9dc534fff352b413de81dfddfba9f4d0990f079c',\n",
    "    'fdc354d08984f0b36be818b8a287a767cad727ed',\n",
    "    # Environmental Science - Citation Count\n",
    "    'a765ee092121aadc1ecc0c36a3240f9e9ea178e8',\n",
    "    '88df709c39fd7b19104d7cf878c990da617192d1',\n",
    "    'd571963a597742e6aa80f43db9446517501b3e20',\n",
    "    '9f5407ba528658f641d236bf9d601c7b3ed81e2f',\n",
    "    'c1e25afc8eba2f505f38c68843ee23d97470dbaa',\n",
    "    'b49fcb19d397ad2120e5219f3d0aef33879abb6a',\n",
    "    # Geography - Prizewinners (Vautrin Lud Prize)\n",
    "    '0554e5abd44b7c0edad0575b8a327c32f443d942',\n",
    "    '79d8c6b940ed9524f11a59ce891968d17b335ed5',\n",
    "    '10f3a1d8ecf0df2993a3cf679ff31e01ce32cff7',\n",
    "    '05eba6fe8603ae0a564022fb4fe9faed0454afd1',\n",
    "    '7a9cce42bbc8c8ab6bd6196c1f5fabbf87f19e5b',\n",
    "    # Geography - Citation Count\n",
    "    'c0d6f96ffc156bab46fe3097f8a50de5a62eb9f4',\n",
    "    '2bfd55d8612c872122499417b9de1c70cda9f562',\n",
    "    '6aabdd609b09fbd1c9244a8db33155b3feaf604a',\n",
    "    '310ba0bc8e14e96c1a0566b1dae57c77a960de12',\n",
    "    '497e2542e47e4c0fe8b4051f13ea6e0c6fdd6bde',\n",
    "    # Geology - Prizewinners (Vetlesen Prize, Wollaston Medal, Penrose Medal)\n",
    "    '075d5f246c30a6ec5acf8f3f2ef415d20981fa81',\n",
    "    'eaa7d6df21e3a097ab902e19ff2f2905aafb7ab3',\n",
    "    '8d5fc8de8f5e05b1911c4dac9826e64575c97e22',\n",
    "    'f5f465ae3fb26f4256c8005b667794e0a6377d31',\n",
    "    '67f5af9e020107e032b26d3ea293e5c48b84ced9',\n",
    "    # Geology - Citation Count\n",
    "    'af8d81f43ea661762b5c1debda4320afe2c28265',\n",
    "    '2693cac78b1de1ef98ac90b8b704525985359f60',\n",
    "    '55cd56bab78f7e686810acb7dd244a8cf0c18ccf',\n",
    "    '37c13877e62e988868293c19239fe8389a213c7d',\n",
    "    '13a2ead81b81a2abefc31a25f2af26a374ca1cb2',\n",
    "    # History - Prizewinners (Pulitzer Prize for History)\n",
    "    '9d3556bf7d2bc0e43f37aae1117e1fb2ea1b8b3c',\n",
    "    'd510f874940b5b7d9ced2196182119156c3a4aa6',\n",
    "    '3cd456ad75f18addaf2e98e821854a7749f58dcd',\n",
    "    'a756098d7ca6017a31192216a14d67d163c8f70b',\n",
    "    'a899f63b436aa9d06141bb5ea8edc69f32cb8eb9',\n",
    "    # History - Citation Count\n",
    "    '84ed742c2ecda9f3960575b92ce84796d6061906',\n",
    "    '796aaef0da73624ae5439d42465c1d7098a3f430',\n",
    "    '4415d3f35bcc2525c03630924780b9f5ef06eacd',\n",
    "    'df3d2f2c490ec5279b171189087ba7902fdd6603',\n",
    "    'd801a133aa8717c34dcfd4ea86f3d5f91dbdb0fd',\n",
    "    'e3df8744a7843a48b6591c1cf439db12a1257bd2',\n",
    "    # Law - Prizewinners (War schwierig... Stockholm Prize in Criminology und zusätzliche Paper wie in Law - Citation Count und Anthony Bradley Prize von Edinburgh Law School)\n",
    "    '96d7859d70bd6e9eeb4827f892592f117c49c1fd',\n",
    "    '615f6a06bab74056c43997940cca02eaefe56721',\n",
    "    '94abff3a3142809bd205254e34776647f83657d6',\n",
    "    '1c26a95b13c69234a7f6426add92df5c53e035ea',\n",
    "    'fbf58d40593b7207d3d5fe9068681e22a05d9d87',\n",
    "    'be2774f0fa504ac0c9387645f7c79a93a804b8db',\n",
    "    # Law - Citation Count\n",
    "    '711a36f214aaa6438bcb7250e7b902992b3fb878',\n",
    "    'e102c6fa4a720e32583e25822bb63d34174af1af',\n",
    "    # 'Corpus ID: 32200690', NONE-TYPE\n",
    "    '16cbfba326248c9051a97bce4d6edd67e95c6be8',\n",
    "    'd3a0d52d8a0e94f8a7cec5d7d5db684024573537',\n",
    "    # Linguistics - Prizewinners (E.W. Beth Dissertation Prize, Linguapax Prize)\n",
    "    'ccfa90f05ddf7c5fe2ea83b64a58285eace8e135',\n",
    "    '02fe377dc583cd10d0f5e042627f1e43c6531a8f',\n",
    "    'dae0cf248c7f3482663baa55330de22662d39a80',\n",
    "    'd6bb4f3b28e97c20d8c58af5cd9751fe1ef905d9',\n",
    "    'fdcc6cdc5be85455e138c0d97f58e6084394a0e4',\n",
    "    '26e408cd6a0213bcbed83290bcb2edfc7346c859',\n",
    "    # Linguistics - Citation Count\n",
    "    '3ac11ca7c2e3e81159c67d8e2f753574e72046c1',\n",
    "    '7ba33b812df45064ab0ddda8059a9da4258ffb1e',\n",
    "    '4bcac104568f8aef9d82abc76250c11e8a309297',\n",
    "    'b1e48825c647aeeb9c37250a93e863fb4eb77124',\n",
    "    '8ec7a7b28f5237fa429e380f266f33548f3cff59',\n",
    "    # Materials Science - Prizewinners (Von Hippel Award)\n",
    "    'd224a1027b47cece2982c400162e053192423b1b',\n",
    "    'b1bde690f0500785e0fe93ca6e01300ae649aa9d',\n",
    "    'fe297418763154fa4a17273011c11da2c58e42d2',\n",
    "    '3e88d99a60d1ed795d8a07fe90587f2828132506',\n",
    "    '19128a8a410bab123ea5ab69fa8a5efd0be2d1f7',\n",
    "    # Materials Science - Citation Count\n",
    "    '300f6e755d2e1fd1e3c42804c724f988b7b0e1a1',\n",
    "    '49c4bc07b0047425117d89935c27aa4d22c5c174',\n",
    "    'bb29163f8f6344695310348c66cec412acbf428b',\n",
    "    '7ad70a564c4c8898f61eddbcecf9e90f71e9d4b6',\n",
    "    'd0ed27e58992eb1d289d35f7b902e5b26688af38'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramses_paper_list = [\n",
    "    # Mathematics - Prizewinners                                     (Ramses)\n",
    "    '37b0ec9dc369dcda843cf88755bf44522a11a7c9',\n",
    "    'ece822593c903e234820c6c7da060654aacaed38',\n",
    "    '23b18110e67223e6b17a530053dc677ba501c636',\n",
    "    '7d2333730401777adad2f30afe6af807fc22e31c',\n",
    "    '53be251f8eaf26027db63a46052b1d8a7dd86684',\n",
    "    # Mathematics - Citation Count\n",
    "    'c0cd4b4844c31a27a7900a754d0a91b160b00e55',\n",
    "    'c9c852bc0e8774336734ff339c1592b2cf2d849f',\n",
    "    '9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b',\n",
    "    '92d5f6f2d13484c688ca4c08c1279229ba266089',\n",
    "    'e60bd78ca8621c3938f740947d985c2ea5ff5d67',\n",
    "    # Medicine - Prizewinners\n",
    "    'be75109902f5689f7114e9e0fa783a12ceaa9b3a',\n",
    "    '9632ca098599970f1795dcc5d4d5ae5a8d2f182d',\n",
    "    '29039649db9dc86bb6396b18c4f99fc525606dd9',\n",
    "    '335ac605e1f46efe2e5e62d75b376c70cdbb59ec',\n",
    "    'af55a840fb0c6e4004c4acfff588c5a7862251bd',\n",
    "    # Medicine - Citation Count\n",
    "    '951865c6d89e9e7822700dad42caf8bd29896d48',\n",
    "    'c416071f485c1d220792c56682cd09a5443eced1',\n",
    "    'f134abeaf9bfd41f29b97aec675ec31895bf541d',\n",
    "    'a0b2f25195269092afe516ce68caec8dfad33ac9',\n",
    "    '6365c7e578b3ba30b85560515f8b7956a2a915cd',\n",
    "    # Philosophy - Prizewinners\n",
    "    '59711cdc12249347d94ce81b4168c1363b0bf994',\n",
    "    'a627cb00f25a916df243e16ea0ae7d0268f951ca',\n",
    "    '3e7505d16145d3aa154c28caaab83d424b907a0d',\n",
    "    '1796b1d9fdf737db18552dcc6b88dfda4ed03aca',\n",
    "    'ef8cf4de553248d1ffe2e79a01a33265284187cc',\n",
    "    # Philosophy - Citation Count\n",
    "    'c19d65d5097d23cdf0bcd11f1c58c8924254b5d2',\n",
    "    '7fe9b067babc0812c1f31b04626397111635fa9d',\n",
    "    '72ef83b0d5bb0be184b7730949d6ef7241a8b02d',\n",
    "    '69cfb48c45b59243d60342b796dbac35e9efd6bc',\n",
    "    'a9ca9fe75c9cbe15754481a5baa6d85593c8fae0',\n",
    "    # Physics - Prizewinners\n",
    "    '7658efad8951194bc7c7e8a3709c5a30660bc893',\n",
    "    'd0c9b48422ff2239477b183c2211e20eaea795ab',\n",
    "    '8cec28449f2f21e79c46b0e51fe9f8669c5c500e',\n",
    "    '286f60799abe6a47f7da040cb875de170eb56bb4',\n",
    "    '1a4e35f65bb43146795b46ab4e3f525348349044',\n",
    "    'e6ecd94a6256798f2cfaf3cfeda4906eb3bca1e7',\n",
    "    # Physics - Citation Count\n",
    "    '47552b2aa5f1137bc46b01daa91b9175837cc380',\n",
    "    'e1d1e7dc2606b1d60cb85057ab7c5bbd52067661',\n",
    "    '8823290166bf24efc7cfda4d251f959b5f5f8e4c',\n",
    "    'b9bdcbf59cf6f65b60b47004cfa85f1eeb3bbad7',\n",
    "    '060a3c0274fb07daeeb85aa46b191f862abd8a09',\n",
    "    # Political Science - Prizewinners\n",
    "    '97efee042acc9673a81e6fa106f3680d4a03852c',\n",
    "    '2fadc276a5aec2c417337f6bf29c976bddd2f03f',\n",
    "    '40a8e9a91a059277fbe9cfd12e9877013024fc75',\n",
    "    '87392ddf2fd4102df9b3bf411edbeb83e065075d',\n",
    "    '6074dc981d7f07b866039a7b856d51ce966331bc',\n",
    "    # Political Science - Citation Count\n",
    "    '1e863a09164d94eb1553bb0a100be974dfe904ff',\n",
    "    '82baedbe57a232a83bea6d88f16d66cf4acdca64',\n",
    "    # 'DOI:10.1201/9781482246582', NONE-TYPE\n",
    "    '74d0e14c7aa617a43875d6cef35c4622d1305949',\n",
    "    '4323935e72706086995184a39c7f21e66eebe200',\n",
    "    # Psychology - Prizewinners\n",
    "    '9e607237e70fa3129da500ea1137a0d5d8633ddb',\n",
    "    'bc9e4479b0ff89a10ca0e1e88a6b5af8ed3e1354',\n",
    "    '36b332ac960663cea94abc5dbf515d831bfaff36',\n",
    "    'c7fbea9d039e93fc721f0cd1538b5ac04b4f0e73',\n",
    "    'f63d07713b1d7ce3cd8110e7ba839e2d265e9b59',\n",
    "    # Psychology - Citation Count\n",
    "    '98882d201890680e156fef2b111630f401168092',\n",
    "    'a5bca3e6a7fa2135e566f040926a9687cc3ae7f9',\n",
    "    'bbbff45c27dccd114818ef334075db0a34b0e4fa',\n",
    "    '6ea24fcbbe780ce565251757b0a8cec5c753b90d',\n",
    "    'c15e53dffbfe2c6283238e7eeade33256808dbbe',\n",
    "    # Sociology - Prizewinners\n",
    "    '4f4eefbc67c748af2eafeeae3466bb9b5b23ebe1',\n",
    "    '3e99c32b4e16d72ea22e9121a43b0b2795623da5',\n",
    "    'bc6afc8a0406620d51bf897f5cd1114d0edf13b5',\n",
    "    '1f6a9d39bd40e131983aaf03f384fd4f10151de8',\n",
    "    '6586435c044fdf48a74e86dea02902dc235038cf',\n",
    "    # Sociology - Citation Count\n",
    "    '96131e374caf8b0b4cf7e205246d9feeb69d09a4',\n",
    "    '6e29a07906289012958cfa8d05d466cea1f050a1',\n",
    "    '61090d286c2b456efbacfbbc718b1365a80ad39d',\n",
    "    'ee1f75f1978fb173cef9909aea610fa9513afc4f',\n",
    "    'bd3346568eac5ff36de480128ec8ae051482ffe4'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere Category aus Dict\n",
    "def extractCategory(row):\n",
    "    cat_list = []\n",
    "    if row != None:\n",
    "        for value in row:\n",
    "            cat_list.append(value.get('category'))\n",
    "    \n",
    "    return cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere Authoren-Liste\n",
    "def extractAuthorNames(row):\n",
    "    author_list = []\n",
    "    if row != None:\n",
    "        for value in row:\n",
    "            author_list.append(value.get('name'))\n",
    "\n",
    "    return author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere AuthorenId-Liste\n",
    "def extractAuthorIds(row):\n",
    "    authorId_list = []\n",
    "    if row != None:\n",
    "        for value in row:\n",
    "            authorId_list.append(value.get('authorId'))\n",
    "\n",
    "    return authorId_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere Affiliations-Liste\n",
    "def extractAuthorAffiliations(row):\n",
    "    affiliation_list = []\n",
    "    if row != None:\n",
    "        for value in row:\n",
    "            affiliation_list.append(value.get('affiliations'))\n",
    "\n",
    "    return affiliation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere Journalseiten, welche durch das Paper eingenommen werden\n",
    "def extractOccupiedJournalPagesCount(journalPages):\n",
    "    # Belegte Seiten des Journals in dem das Paper veröffentlicht wurde berechnen\n",
    "    # Manche Angaben werden in ihrer Schreibweise verkürzt... z.B.: 153-57, dies soll wie 153-157 behandelt werden, da sonst negative Zahlen bei der folgenden Berechnung entstehen.\n",
    "\n",
    "    try:\n",
    "        split_pages = journalPages.strip().replace('–', '-').split('-')\n",
    "\n",
    "        try:\n",
    "            page_from = split_pages[0]\n",
    "            page_to = split_pages[1]\n",
    "            pagesOccupiedCount = int(page_to)-int(page_from)\n",
    "\n",
    "            if pagesOccupiedCount<0:\n",
    "                # Seitenzahl ist negativ (Seitenzahl von page_from war größer als Seitenzahl von page_to!)\n",
    "                digit_delta = len(page_from)-len(page_to)\n",
    "                # Z.B.: 133-38 wird geschaut aus wie vielen Zahlen beide aufgespaltenen Strings bestehen. Es wird die Länge verglichen, in dem Beispiel hat Zahl an [Index 0] 1 Stelle mehr als die Zahl an [Index 1].\n",
    "                # Es wird nun von der Zahl an [Index 0] der Differenz entsprechend viele Zahlen von Links nach Rechts entnommen und an die Zahl an [Index 1] vorne angefügt.\n",
    "                # So wird aus der Seitenzahl 38 nach diesem Muster [1]33 - [1]38 (die 1 der ersten Zahl wird vorne an die zweite Zahl angefügt).\n",
    "                page_fixed = page_from[0:digit_delta]+page_to\n",
    "                pagesOccupiedCount = int(page_fixed)-int(page_from)\n",
    "                return pagesOccupiedCount\n",
    "            else:\n",
    "                return pagesOccupiedCount\n",
    "                \n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metadata of papers in paperlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.abspath('./datasets/altmetric_yearly_top100/')\n",
    "\n",
    "files = os.listdir(cwd)\n",
    "\n",
    "altmetric_yearly_top100_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        altmetric_yearly_top100_df = altmetric_yearly_top100_df.append(pd.read_excel('./datasets/altmetric_yearly_top100/' + file).rename({'doi': 'DOI'}, axis=1), ignore_index=True)\n",
    "    elif file.endswith('.csv'):\n",
    "        altmetric_yearly_top100_df = altmetric_yearly_top100_df.append(pd.read_csv('./datasets/altmetric_yearly_top100/' + file, sep=',').rename({'doi': 'DOI'}, axis=1), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "altmetric_yearly_top100_df = altmetric_yearly_top100_df.sample(325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "altmetric_list = altmetric_yearly_top100_df[(~(altmetric_yearly_top100_df['Altmetric Attention Score'].isna())) & (altmetric_yearly_top100_df['DOI']!=0) & (~altmetric_yearly_top100_df['DOI'].isna()) & (~altmetric_yearly_top100_df['DOI'].str.contains('http', na=False))]['DOI'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPaperMetadata(paper_list):\n",
    "    start_ts = dtime.now().replace(microsecond=0)\n",
    "    api_key = 'rGUKYOEpCP2FKQK88CLuB1izZBvDiQwA5SsSZ5vo'\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/batch?fields=title,referenceCount,citationCount,influentialCitationCount,externalIds,authors.name,fieldsOfStudy,s2FieldsOfStudy,year,journal'\n",
    "    req = requests.post(url=url, json={'ids': paper_list}, params={'x-api-key': api_key}).json()\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(req)\n",
    "    except:\n",
    "        print(req)\n",
    "\n",
    "    df['authorIds'] = df['authors'].apply(extractAuthorIds)\n",
    "    df['authorsCount'] = df['authorIds'].apply(lambda x: len(x))\n",
    "    df['authors'] = df['authors'].apply(extractAuthorNames)\n",
    "    \n",
    "    try:\n",
    "        df.insert(1, column='DOI', value=df['externalIds'].apply(lambda x: x.get('DOI')), allow_duplicates = False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df.insert(2, column='CorpusId', value=df['externalIds'].apply(lambda x: x.get('CorpusId')), allow_duplicates = False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df['occupiedJournalPages'] = df['journal'].apply(lambda x: extractOccupiedJournalPagesCount(x.get('pages')))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df['journalName'] = df['journal'].apply(lambda x: x.get('name'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df['s2FieldsOfStudy'] = df['s2FieldsOfStudy'].apply(lambda x: extractCategory(x))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df['fieldsOfStudy'] = [ [] if x is None or x is np.NaN else x for x in df['fieldsOfStudy'] ]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Combine FoS & s2FoS\n",
    "        df['fieldsOfStudy'] = df['fieldsOfStudy']+df['s2FieldsOfStudy']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Remove duplicates from the created list\n",
    "        df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(lambda row: sorted(list(dict.fromkeys(row))))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    end_ts = dtime.now().replace(microsecond=0)\n",
    "    print('Collected Metadata of ' + str(df.shape[0]) + ' scientific papers. [Time elapsed: ' + str(end_ts-start_ts) + ']')\n",
    "\n",
    "    return df.drop(['externalIds', 's2FieldsOfStudy', 'journal'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erweitern des Datensatzes mit Metadaten von Papern aus dem Quellenverzeichnis der \"Handpicked-Paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReferenceDataFrame(paperId):\n",
    "    api_key = 'rGUKYOEpCP2FKQK88CLuB1izZBvDiQwA5SsSZ5vo'\n",
    "    offset = 0\n",
    "    df = pd.DataFrame()\n",
    "    start_ts = dtime.now().replace(microsecond=0)\n",
    "\n",
    "    # Get References Data\n",
    "    while offset != None:\n",
    "        try:\n",
    "            # print('Offset: '+str(offset))\n",
    "            url = \"https://api.semanticscholar.org/graph/v1/paper/\"+paperId.replace(' ','').strip()+\"/references?fields=title,referenceCount,citationCount,influentialCitationCount,isInfluential,fieldsOfStudy,s2FieldsOfStudy,year,journal,authors,externalIds&limit=1000&offset=\"+str(offset)\n",
    "            req = requests.get(url=url, params={'x-api-key': api_key}).json()\n",
    "        \n",
    "            # Wait 5 Minutes and retry if API-Server sends 'Too Many Requests'\n",
    "            while req.get('message') == 'Too Many Requests':\n",
    "                print('[Too Many Requests]: Waiting 5 minutes.')\n",
    "                time.sleep((60*5)+5) # Wait 5 Minutes + 5 Extra-seconds for tolerance\n",
    "                url = \"https://api.semanticscholar.org/graph/v1/paper/\"+paperId.replace(' ','').strip()+\"/references?fields=title,referenceCount,citationCount,influentialCitationCount,isInfluential,fieldsOfStudy,s2FieldsOfStudy,year,journal,authors,externalIds&limit=1000&offset=\"+str(offset)\n",
    "                req = requests.get(url=url, params={'x-api-key': api_key}).json()\n",
    "            \n",
    "            df = pd.concat([df, pd.DataFrame(req.get('data'))])\n",
    "            offset = req.get('next')\n",
    "        except Exception as e:\n",
    "            # print('An error was returned from the API-Server while querying the paper with paperId: ' + str(paperId) + '.. Proceeding with next row.')\n",
    "            print(e)\n",
    "    try:\n",
    "        try:\n",
    "            df = df[['isInfluential']].reset_index(drop=True).join(pd.json_normalize(df['citedPaper']))\n",
    "        except:\n",
    "            # No References found.\n",
    "            return\n",
    "            # df = pd.json_normalize(df['citedPaper'])\n",
    "\n",
    "        # Remove rows with missing Ids\n",
    "        if df[df['paperId'].isna()].shape[0]>0:\n",
    "            # missing_row_count = df[df['paperId'].isna()].shape[0]\n",
    "            # print('Removed ' + str(missing_row_count) + ' rows which had missing paperId and external Ids.')\n",
    "            df = df[~df['paperId'].isna()]\n",
    "\n",
    "        df['s2FieldsOfStudy'] = df['s2FieldsOfStudy'].apply(lambda x: extractCategory(x))\n",
    "\n",
    "        # df['fieldsOfStudy'] = [ [] if x is None else x for x in df['fieldsOfStudy'] ] + df['s2FieldsOfStudy']\n",
    "        df['fieldsOfStudy'] = [ [] if x is None or x is np.NaN else x for x in df['fieldsOfStudy'] ]\n",
    "\n",
    "        # Combine foS & s2FoS\n",
    "        df['fieldsOfStudy'] = df['fieldsOfStudy']+df['s2FieldsOfStudy']\n",
    "\n",
    "        # Remove duplicates from the created list\n",
    "        df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(lambda row: sorted(list(dict.fromkeys(row))))\n",
    "\n",
    "        # Belegte Seiten des Journals in dem das Paper veröffentlicht wurde berechnen\n",
    "        try:\n",
    "            # Manche Angaben werden in ihrer Schreibweise verkürzt... z.B.: 153-57, dies soll wie 153-157 behandelt werden, da sonst negative Zahlen bei der folgenden Berechnung entstehen.\n",
    "            df['occupiedJournalPages'] = df['journal.pages'].apply(lambda journalPages: extractOccupiedJournalPagesCount(journalPages))\n",
    "        except:\n",
    "            df['occupiedJournalPages'] = 0\n",
    "\n",
    "        # Author Name extrahieren\n",
    "        df['authorsCount'] = df['authors'].apply(lambda x: len(x))\n",
    "        df['authorIds'] = df['authors'].apply(extractAuthorIds)\n",
    "        df['authors'] = df['authors'].apply(extractAuthorNames)\n",
    "\n",
    "        # Author Affiliation extrahieren\n",
    "        # df['authors_affiliations'] = df['authors'].apply(lambda x: extractAuthorAffiliations(x))\n",
    "\n",
    "        # Dtype conversion\n",
    "        # df['year'] = df['year'].astype(int)\n",
    "        df['referenceCount'] = df['referenceCount'].astype(int)\n",
    "        df['citationCount'] = df['citationCount'].astype(int)\n",
    "        df['influentialCitationCount'] = df['influentialCitationCount'].astype(int)\n",
    "\n",
    "        # if missing_row_count>0:\n",
    "        #     print('Collected ' + str(df.shape[0]) + ' row(s), removed ' + str(missing_row_count) + ' row(s) due to missing Id. (For Details check: www.semanticscholar.org/paper/' + paperId + ') [Time elapsed: ' + str((end_ts-start_ts)) + ']')\n",
    "        # else:\n",
    "        #     print('Collected ' + str(df.shape[0]) + ' row(s). [Time elapsed: ' + str((end_ts-start_ts)) + ']')\n",
    "\n",
    "        df.insert(0, 'Ref_paperId', paperId)\n",
    "        try:\n",
    "            df.insert(loc=1, column='DOI', value=df['externalIds.DOI'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for col in df.columns:\n",
    "            if 'externalIds' in col:\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "        potential_cols_to_be_dropped = ['isInfluential', 's2FieldsOfStudy','publicationVenue.id', 'publicationVenue.issn', 'publicationVenue.name',\t'publicationVenue.type', 'publicationVenue.alternate_issns', 'publicationVenue.url', 'publicationVenue.alternate_urls', 'journal.volume', 'journal.pages', 'journal', 'publicationVenue.alternate_names', 'publicationVenue']\n",
    "        for col in potential_cols_to_be_dropped:\n",
    "            try:\n",
    "                df.drop([col], axis=1, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        end_ts = dtime.now().replace(microsecond=0)\n",
    "        print('Collected Metadata of ' + str(df.shape[0]) + ' scientific papers. [Time elapsed: ' + str(end_ts-start_ts) + ']')\n",
    "\n",
    "        return df.rename({'journal.name': 'journalName'}, axis=1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erweitern der Datensätze (basierend auf Quellenverzeichnis der handpicked-papers + handpicked-papers selbst) um Autoren Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthorData(author_list):\n",
    "    try:\n",
    "        api_key = 'rGUKYOEpCP2FKQK88CLuB1izZBvDiQwA5SsSZ5vo'\n",
    "        url = 'https://api.semanticscholar.org/graph/v1/author/batch?fields=name,paperCount,citationCount,hIndex'\n",
    "        req = requests.post(url=url, json={'ids': author_list}, params={'x-api-key': api_key})\n",
    "\n",
    "        # Wait 5 Minutes and retry if API-Server sends 'Too Many Requests'\n",
    "        while req.status_code == 429: # Too Many Requests\n",
    "            print('[Too Many Requests]: Waiting 5 minutes.')\n",
    "            time.sleep((60*5)+5) # Wait 5 Minutes + 5 Extra-seconds for tolerance\n",
    "            req = requests.post(url=url, json={'ids': author_list}, params={'x-api-key': api_key})\n",
    "        \n",
    "        try:\n",
    "            df = pd.DataFrame(req.json())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Get the Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "influential_papers_list = hamza_paper_list+maurice_paper_list+ramses_paper_list+altmetric_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get Semantic Scholar Paper and References Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ss_df from disk. (19508 rows; 15 columns)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./exports/ss_df.csv'):\n",
    "    # Sicherungskopie einlesen, falls der Code nach der Abfrage der Referenzen abgestürzt sein sollte.\n",
    "    ss_df = pd.read_csv('./exports/ss_df.csv', sep=',')\n",
    "    print('Loaded ss_df from disk. (' + str(ss_df.shape[0]) + ' rows; ' + str(ss_df.shape[1]) + ' columns)')\n",
    "else:\n",
    "    try:\n",
    "            ss_df = getPaperMetadata(influential_papers_list)\n",
    "            print('Collecting Semantic Scholar Reference Data...')\n",
    "            reference_df = pd.DataFrame()\n",
    "            start_ts = dtime.now().replace(microsecond=0)\n",
    "            for idx, paper in enumerate(influential_papers_list):\n",
    "                # print('[' + str(idx+1) + '] ------------------------ Paper: ' + str(paper) + ' ------------------------')\n",
    "                reference_df = pd.concat([reference_df, getReferenceDataFrame(paper)])\n",
    "            reference_df = reference_df.drop_duplicates(subset=['paperId'])\n",
    "            end_ts = dtime.now().replace(microsecond=0)\n",
    "            print('- Colleted ' + str(reference_df.shape[0]) + ' paper(s). [Time elapsed: ' + str((end_ts-start_ts)) + ']')\n",
    "    except Exception as e:\n",
    "        print('- Failed to collect Semantic Scholar References metadata.')\n",
    "\n",
    "    ss_df = ss_df.append(reference_df)\n",
    "    ss_df.insert(0, 'Ref_paperId', ss_df.pop('Ref_paperId'))\n",
    "    print('- Appended Reference DataFrame to \"ss_df\" for future processing.')\n",
    "\n",
    "    if os.path.exists('./exports/') == False:\n",
    "        os.mkdir('./exports/')\n",
    "\n",
    "    # Remove rows with missing DOIs since it's impossible to query other APIs like Altmetric for these cases\n",
    "    ss_df.dropna(subset=['DOI'], inplace=True)\n",
    "\n",
    "    # Remove rows with duplicate subsets of paperId and DOI since it can be possible for multiple handpicked-papers cite the same paper as one of their sources\n",
    "    ss_df.drop_duplicates(['paperId', 'DOI'], keep='first', inplace=True)\n",
    "\n",
    "    ss_df.to_csv('./exports/ss_df.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get Altmetric Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded altmetric_df from disk. (rows: 12607; columns: 23)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./exports/altmetric_df.csv'):\n",
    "    # Sicherungskopie einlesen, falls der Code nach der Abfrage der Referenzen abgestürzt sein sollte.\n",
    "    altmetric_df = pd.read_csv('./exports/altmetric_df.csv', sep=',')\n",
    "    print('Loaded altmetric_df from disk. (rows: ' + str(altmetric_df.shape[0]) + '; columns: ' + str(altmetric_df.shape[1]) + ')')\n",
    "\n",
    "    # Before Merging make DOIs uppercase\n",
    "    ss_df['DOI'] = ss_df['DOI'].str.upper()\n",
    "    altmetric_df['altmetric_doi'] = altmetric_df['altmetric_doi'].str.upper()\n",
    "\n",
    "    # Merge Altmetric with Semantic Scholar Reference Data\n",
    "    ss_df = ss_df.merge(altmetric_df, how='left', left_on='DOI', right_on='altmetric_doi').drop(['altmetric_doi'], axis=1)\n",
    "else:\n",
    "    try:\n",
    "        print('- Collecting Altmetric Data...')\n",
    "        start_ts = dtime.now().replace(microsecond=0)\n",
    "        altmetric_list = []\n",
    "        for idx, paper in enumerate(ss_df[~ss_df['DOI'].isna()]['DOI'].unique()):\n",
    "            print('[' + str(idx+1) + '] ---------- Collecting data for <' + str(paper) + '> ----------')\n",
    "            altmetric_list = altmetric_list+[getAMdata(paper)]\n",
    "        altmetric_df = pd.DataFrame([i for i in altmetric_list if i is not None])\n",
    "        end_ts = dtime.now().replace(microsecond=0)\n",
    "        print('- Colleted ' + str(altmetric_df.shape[0]) + ' paper(s) Altmetric data. [Time elapsed: ' + str((end_ts-start_ts)) + ']')\n",
    "        \n",
    "        # Export Altmetric_df to csv\n",
    "        altmetric_df.to_csv('./exports/altmetric_df.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "        # Before Merging make DOIs uppercase\n",
    "        ss_df['DOI'] = ss_df['DOI'].str.upper()\n",
    "        altmetric_df['altmetric_doi'] = altmetric_df['altmetric_doi'].str.upper()\n",
    "\n",
    "        # Merge Altmetric with Semantic Scholar Reference Data\n",
    "        ss_df = ss_df.merge(altmetric_df, how='left', left_on='DOI', right_on='altmetric_doi').drop(['altmetric_doi'], axis=1)\n",
    "    except:\n",
    "        print('Failed to collect Altmetric data.')\n",
    "\n",
    "    # Drop potential duplicates\n",
    "    ss_df.drop_duplicates(['paperId', 'DOI'], inplace=True)\n",
    "\n",
    "try:\n",
    "    # Convert String-Column to List\n",
    "    ss_df['authorIds'] = ss_df['authorIds'].apply(literal_eval)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get Authors Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded authors_df from disk. (rows: 67364; columns: 5)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./exports/authors_df.csv'):\n",
    "    # Sicherungskopie einlesen, falls der Code nach der Abfrage der Referenzen abgestürzt sein sollte.\n",
    "    authors_df = pd.read_csv('./exports/authors_df.csv', sep=',')\n",
    "    print('Loaded authors_df from disk. (rows: ' + str(authors_df.shape[0]) + '; columns: ' + str(authors_df.shape[1]) + ')')\n",
    "else:\n",
    "    try:\n",
    "        print('- Collecting Semantic Scholar Author Data...')\n",
    "        authors_df = pd.DataFrame()\n",
    "        # Tell Pandas to recognize 'authorIds' as List, otherwise it will be handled as if it was a String and then the following code snippet won't work\n",
    "        try:\n",
    "            ss_df['authorIds'] = ss_df['authorIds'].apply(literal_eval)\n",
    "        except:\n",
    "            pass\n",
    "        ssAuthors = ss_df['authorIds'].explode().unique().tolist()\n",
    "        # Remove missing values from list\n",
    "        ssAuthors = [x for x in ssAuthors if x not in [None, np.nan, 'nan']]\n",
    "\n",
    "        for authors in range(0, len(ssAuthors), 1000):\n",
    "            authors_df = authors_df.append(getAuthorData(ssAuthors[authors:authors+1000]))\n",
    "            print('Collected Authors [' + str(authors_df.shape[0]) + '/' + str(len(ssAuthors)) + ']')\n",
    "        \n",
    "        # try:\n",
    "        #     print('Checking if the author is a Nobel Prize laureate.')\n",
    "        #     authors_df['isNobelPrizeLaureate'] = authors_df['name'].apply(isNobelPrizeLaureate)\n",
    "        # except:\n",
    "        #     print('Error occured checking Nobel Prize Laureates.')\n",
    "\n",
    "        authors_df.to_csv('./exports/authors_df.csv', encoding='utf-8-sig', index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Failed to collect author data from Semanticscholar.org')\n",
    "\n",
    "authors_df['authorId'] = authors_df['authorId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorId</th>\n",
       "      <th>name</th>\n",
       "      <th>paperCount</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>hIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57672</th>\n",
       "      <td>1892901</td>\n",
       "      <td>T. Agócs</td>\n",
       "      <td>75</td>\n",
       "      <td>1963</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55007</th>\n",
       "      <td>101130934</td>\n",
       "      <td>K. Soroka</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>39099576</td>\n",
       "      <td>T. Omata</td>\n",
       "      <td>182</td>\n",
       "      <td>3395</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58211</th>\n",
       "      <td>1403427003</td>\n",
       "      <td>Z. Saz-Parkinson</td>\n",
       "      <td>66</td>\n",
       "      <td>988</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40692</th>\n",
       "      <td>8391563</td>\n",
       "      <td>V. Smolčić</td>\n",
       "      <td>188</td>\n",
       "      <td>14934</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         authorId              name  paperCount  citationCount  hIndex\n",
       "57672     1892901          T. Agócs          75           1963      14\n",
       "55007   101130934         K. Soroka           3            175       2\n",
       "15975    39099576          T. Omata         182           3395      29\n",
       "58211  1403427003  Z. Saz-Parkinson          66            988      15\n",
       "40692     8391563        V. Smolčić         188          14934      54"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculate aggregated Author KPIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .explore() macht aus einer Liste mit Werten neue separate Zeilen [1, 2, 3] ->  drei separate Zeilen, die bis auf die für .explode() genutzte Spalte identisch sind.\n",
    "ss_df_exploded = ss_df.explode('authorIds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Scholar DataFrame mit Authoren DataFrame mergen\n",
    "ss_df_exploded = ss_df_exploded[['paperId', 'authorIds']].merge(authors_df.rename({'paperCount':'authors_sum_paperCount', 'citationCount':'authors_sum_citationCount', 'hIndex':'authors_sum_hIndex'}, axis=1), how='left', left_on=['authorIds'], right_on=['authorId']).sort_values(by=['paperId']).drop(['authorIds', 'name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventuelle Duplikate entfernen\n",
    "ss_df_exploded.drop_duplicates(subset=['paperId', 'authorId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authors_sum_paperCount</th>\n",
       "      <th>authors_sum_citationCount</th>\n",
       "      <th>authors_sum_hIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>e932c974074cc4a38f02fa7d674932eef81faf61</td>\n",
       "      <td>36933375</td>\n",
       "      <td>142.0</td>\n",
       "      <td>12784.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>e932c974074cc4a38f02fa7d674932eef81faf61</td>\n",
       "      <td>50455279</td>\n",
       "      <td>187.0</td>\n",
       "      <td>8791.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>e932c974074cc4a38f02fa7d674932eef81faf61</td>\n",
       "      <td>2106288317</td>\n",
       "      <td>17.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paperId    authorId  \\\n",
       "2276  e932c974074cc4a38f02fa7d674932eef81faf61    36933375   \n",
       "2277  e932c974074cc4a38f02fa7d674932eef81faf61    50455279   \n",
       "2278  e932c974074cc4a38f02fa7d674932eef81faf61  2106288317   \n",
       "\n",
       "      authors_sum_paperCount  authors_sum_citationCount  authors_sum_hIndex  \n",
       "2276                   142.0                    12784.0                58.0  \n",
       "2277                   187.0                     8791.0                50.0  \n",
       "2278                    17.0                      772.0                 7.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df_exploded[ss_df_exploded['paperId']=='e932c974074cc4a38f02fa7d674932eef81faf61']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author KPIs auf Basis der paperId aggregieren\n",
    "ss_df_exploded = ss_df_exploded[['paperId', 'authors_sum_paperCount', 'authors_sum_citationCount', 'authors_sum_hIndex']].groupby(['paperId']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>authors_sum_paperCount</th>\n",
       "      <th>authors_sum_citationCount</th>\n",
       "      <th>authors_sum_hIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17821</th>\n",
       "      <td>e932c974074cc4a38f02fa7d674932eef81faf61</td>\n",
       "      <td>346.0</td>\n",
       "      <td>22347.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        paperId  authors_sum_paperCount  \\\n",
       "17821  e932c974074cc4a38f02fa7d674932eef81faf61                   346.0   \n",
       "\n",
       "       authors_sum_citationCount  authors_sum_hIndex  \n",
       "17821                    22347.0               115.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df_exploded[ss_df_exploded['paperId']=='e932c974074cc4a38f02fa7d674932eef81faf61']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregierte Author KPIs wieder zum ss_df zurückführen\n",
    "ss_df = ss_df.merge(ss_df_exploded, how='left', on=['paperId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Nobel Prize Laureates which contributed to a specific scientific paper and append column\n",
    "ss_df['nobelPrizeLaureatesCount'] = ss_df['authors'].apply(getNobelPrizeLaureateCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19539, 41)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./exports/') == False:\n",
    "    os.mkdir('./exports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df.to_csv('./exports/ss_df_complete.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prepare DataFrame for ML__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for ML with only relevant KPIs\n",
    "ss_df_reduced = ss_df[['paperId', 'referenceCount', 'citationCount', 'authorsCount', 'occupiedJournalPages', 'authors_sum_paperCount', 'authors_sum_citationCount', 'authors_sum_hIndex', 'altmetric_score', 'influentialCitationCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Values with 0\n",
    "ss_df_reduced = ss_df_reduced.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecasting\n",
    "ss_df_reduced.iloc[:, 1:] = ss_df_reduced.iloc[:, 1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>authorsCount</th>\n",
       "      <th>occupiedJournalPages</th>\n",
       "      <th>authors_sum_paperCount</th>\n",
       "      <th>authors_sum_citationCount</th>\n",
       "      <th>authors_sum_hIndex</th>\n",
       "      <th>altmetric_score</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c5d7b0fafdd72f57f2b0bfdd0ce3608a2528b666</td>\n",
       "      <td>0</td>\n",
       "      <td>14055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>64780</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eaa7d6df21e3a097ab902e19ff2f2905aafb7ab3</td>\n",
       "      <td>174</td>\n",
       "      <td>2802</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>41428</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79b4b48c6481becde78bd6287386d6507dac27b1</td>\n",
       "      <td>107</td>\n",
       "      <td>2477</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>81901</td>\n",
       "      <td>189</td>\n",
       "      <td>29</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e87c3be7aaa1c7ce91f94fda0815339ac02af787</td>\n",
       "      <td>103</td>\n",
       "      <td>5112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>55855</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d224a1027b47cece2982c400162e053192423b1b</td>\n",
       "      <td>41</td>\n",
       "      <td>5737</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3487</td>\n",
       "      <td>192943</td>\n",
       "      <td>392</td>\n",
       "      <td>43</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19534</th>\n",
       "      <td>209575bae1041c8be7a2c3f3ff38ab19065d277d</td>\n",
       "      <td>51</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>138</td>\n",
       "      <td>7533</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19535</th>\n",
       "      <td>6b21acc0d164190b9111da7cafd7630f70490c7b</td>\n",
       "      <td>28</td>\n",
       "      <td>868</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>12291</td>\n",
       "      <td>43</td>\n",
       "      <td>418</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19536</th>\n",
       "      <td>7357771111c6160e44a98174ee19e04c3bdd81a5</td>\n",
       "      <td>22</td>\n",
       "      <td>229</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>880</td>\n",
       "      <td>27901</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19537</th>\n",
       "      <td>14f2cdbf971aa34b7d6a911fb0fbdf05c4474b3f</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>7963</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19538</th>\n",
       "      <td>85906a96f45346116f90e3b7c47d054868deb425</td>\n",
       "      <td>6</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>832</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19539 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        paperId  referenceCount  \\\n",
       "0      c5d7b0fafdd72f57f2b0bfdd0ce3608a2528b666               0   \n",
       "1      eaa7d6df21e3a097ab902e19ff2f2905aafb7ab3             174   \n",
       "2      79b4b48c6481becde78bd6287386d6507dac27b1             107   \n",
       "3      e87c3be7aaa1c7ce91f94fda0815339ac02af787             103   \n",
       "4      d224a1027b47cece2982c400162e053192423b1b              41   \n",
       "...                                         ...             ...   \n",
       "19534  209575bae1041c8be7a2c3f3ff38ab19065d277d              51   \n",
       "19535  6b21acc0d164190b9111da7cafd7630f70490c7b              28   \n",
       "19536  7357771111c6160e44a98174ee19e04c3bdd81a5              22   \n",
       "19537  14f2cdbf971aa34b7d6a911fb0fbdf05c4474b3f              30   \n",
       "19538  85906a96f45346116f90e3b7c47d054868deb425               6   \n",
       "\n",
       "       citationCount  authorsCount  occupiedJournalPages  \\\n",
       "0              14055             1                     0   \n",
       "1               2802             2                     0   \n",
       "2               2477             2                     0   \n",
       "3               5112             2                     0   \n",
       "4               5737             6                     0   \n",
       "...              ...           ...                   ...   \n",
       "19534            339             4                     9   \n",
       "19535            868             1                     3   \n",
       "19536            229             6                     5   \n",
       "19537             39             1                     3   \n",
       "19538            147             3                     2   \n",
       "\n",
       "       authors_sum_paperCount  authors_sum_citationCount  authors_sum_hIndex  \\\n",
       "0                         410                      64780                 105   \n",
       "1                         530                      41428                 126   \n",
       "2                         709                      81901                 189   \n",
       "3                         139                      55855                  67   \n",
       "4                        3487                     192943                 392   \n",
       "...                       ...                        ...                 ...   \n",
       "19534                     138                       7533                  54   \n",
       "19535                      86                      12291                  43   \n",
       "19536                     880                      27901                 164   \n",
       "19537                     144                       7963                  53   \n",
       "19538                      36                        832                  20   \n",
       "\n",
       "       altmetric_score  influentialCitationCount  \n",
       "0                    0                       302  \n",
       "1                    3                       332  \n",
       "2                   29                       319  \n",
       "3                   26                       554  \n",
       "4                   43                        92  \n",
       "...                ...                       ...  \n",
       "19534               13                        26  \n",
       "19535              418                        98  \n",
       "19536               29                        10  \n",
       "19537                4                         0  \n",
       "19538                3                         4  \n",
       "\n",
       "[19539 rows x 10 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export für Dashboard\n",
    "ss_df_reduced.to_csv('./exports/ss_df_reduced.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierung mit Min-Max-Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normScaler = MinMaxScaler(feature_range=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform 'ml_df' with Min-Max-Scaler\n",
    "ss_df_normalized = pd.DataFrame(normScaler.fit_transform(ss_df_reduced.drop(['paperId'], axis=1)))\n",
    "ss_df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "ss_df_normalized.columns = ss_df_reduced.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if column contains min of 0 and max of 100\n",
    "ss_df_normalized['citationCount'].min(), ss_df_normalized['citationCount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join back paperId to normalized df\n",
    "ss_df_normalized = ss_df_reduced[['paperId']].join(ss_df_normalized)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Gewichtung berechnen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test-Split\n",
    "train_data, test_data = train_test_split(ss_df_reduced.drop(['paperId'], axis=1),test_size=0.2,random_state=42)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular Predictor laden und Speicherpfad einstellen\n",
    "save_path = './trained_models/weights'\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    predictor = TabularPredictor.load(save_path)\n",
    "    print('Loaded model from disk.')\n",
    "else:\n",
    "    predictor = TabularPredictor(label='influentialCitationCount', path=save_path).fit(train_data, verbosity=0, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Feature Importance ausgeben\n",
    "feature_importance = predictor.feature_importance(data=test_data)[['importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteilsmäßigen Einfluss der Features berechnen\n",
    "feature_importance['total_share'] = round(abs(feature_importance['importance']/feature_importance['importance'].sum()), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = feature_importance[['total_share']].rename({'total_share':'Gewichtung'}, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Weight-Table for Dashboard\n",
    "weight_df.to_csv('./exports/weights.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbd65fc690d3685c1b6e92b591b5d58183363517bb21956099026d3ab3ce8bce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
